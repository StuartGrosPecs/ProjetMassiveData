# **Projet DonnÃ©es Massives & Cloud â€” Benchmark TinyInsta**

Ce projet analyse les performances de lâ€™application **TinyInsta**, un mini-rÃ©seau social permettant de :

* crÃ©er des posts,
* suivre des utilisateurs,
* visualiser une timeline.

Lâ€™objectif est dâ€™Ã©tudier :

* **Lâ€™impact de la concurrence**
* **Lâ€™impact de la taille des donnÃ©es**

---

## **ğŸ”— Webapp GCP dÃ©ployÃ©e**

 [https://projetmassivedata.appspot.com](https://projetmassivedata.appspot.com)

---

# **Structure du dÃ©pÃ´t**

```
â”œâ”€â”€ experiments
â”‚   â”œâ”€â”€ exp1_concurrency
â”‚   â”œâ”€â”€ exp2_datasize
â”‚   â””â”€â”€ wipe_datastore.py
â”œâ”€â”€ massive-gcp-master/      # Backend TinyInsta
â”œâ”€â”€ out/                     # CSV du rendu final
â”‚   â”œâ”€â”€ conc.csv
â”‚   â”œâ”€â”€ post.csv
â”‚   â””â”€â”€ fanout.csv
â”œâ”€â”€ plots/                   # Graphiques finaux
â”‚   â”œâ”€â”€ conc_barplot.png
â”‚   â”œâ”€â”€ post_barplot.png
â”‚   â””â”€â”€ fanout_barplot.png
â””â”€â”€ README.md
```

---

# **2. Initialisation du projet**

## **2.1. Installation & environnement**

```sh
git clone https://github.com/StuartGrosPecs/ProjetMassiveData
cd ProjetMassiveData
python3 -m venv .venv
source .venv/bin/activate
pip install -r massive-gcp-master/requirements.txt
```

---

## **2.2. Configuration GCP**

```sh
gcloud init
gcloud config set project projetmassivedata
```

---

## **2.3. DÃ©ploiement App Engine**

```sh
cd massive-gcp-master
gcloud app deploy
```

Lâ€™application sera accessible ici :
â¡ï¸ [https://projetmassivedata.appspot.com](https://projetmassivedata.appspot.com)

---


# **3. Utilisation des expÃ©riences**

Les trois Ã©tapes sont indÃ©pendantes et doivent Ãªtre lancÃ©es sÃ©parÃ©ment.
---

# **Ã‰tape 1 â€” ExpÃ©rience 1 : Concurrency**

### **Objectif**

Mesurer la latence pour 1, 10, 20, 50, 100 et 1000 requÃªtes simultanÃ©es.

### **1. Seed**

```sh
cd experiments/exp1_concurrency
chmod +x seed_exp1.sh
./seed_exp1.sh
```

### **2. ExÃ©cution du benchmark**

```sh
python3 benchmark_exp1.py
```

    GÃ©nÃ¨re : `out/conc.csv`

### **3. Analyse graphique**

```sh
python3 analyze_exp1.py
```

    Produit : `plots/conc_barplot.png`

---

# **Ã‰tape 2 â€” ExpÃ©rience 2A : Variation du nombre de posts**

### **Objectif**

Tester lâ€™effet de 10, 100, 1000 posts par utilisateur.

### **1. Seed**

```sh
cd experiments/exp2_datasize/posts
chmod +x seed_posts.sh
./seed_posts.sh 10
```

Chaque seed prÃ©pare le Datastore pour le benchmark correspondant.

### **2. ExÃ©cution du benchmark**

```sh
python3 benchmark_exp2_posts.py --posts 10
```

    GÃ©nÃ¨re : `out/post.csv`

**RÃ©pÃ©tez ensuite les Ã©tapes de seed et de benchmark avec les valeurs 100 puis 1000 en paramÃ¨tre.**

### **3. Analyse graphique**

```sh
python3 analyze_exp2_posts.py
```

    Produit : `plots/post_barplot.png`

---

# **Ã‰tape 3 â€” ExpÃ©rience 2B : Variation du fanout (followees)**

### **Objectif**

Tester lâ€™effet de 10, 50, 100 followees.

### **1. Seed (obligatoire)**

```sh
cd experiments/exp2_datasize/fanout
chmod +x seed_fanout.sh
./seed_fanout.sh 10
```

### **2. ExÃ©cution du benchmark**

```sh
python3 benchmark_exp2_fanout.py --followees 10
```

    GÃ©nÃ¨re : `out/fanout.csv`

**RÃ©pÃ©tez ensuite les Ã©tapes de seed et de benchmark avec les valeurs 50 puis 100 en paramÃ¨tre.**

### **3. Analyse graphique**

```sh
python3 analyze_exp2_fanout.py
```

    Produit : `plots/fanout_barplot.png`

---

# **4. Format des CSV** Format des CSV**

Tous les fichiers possÃ¨dent le header :

```
PARAM,AVG_TIME,RUN,FAILED
```

Exemple :

```
10,0.2589,1,0
10,0.1794,2,0
```

---

# **5. Analyse globale**

* Plus la **concurrence** augmente â†’ latence plus Ã©levÃ©e.


---

# **6. Nettoyage du Datastore**

```sh
cd experiments
python3 wipe_datastore.py
```


# **7. Outils**

Pour vÃ©rifier le contenu du Datastore :
```sh
python3 tools/count_posts.py
python3 tools/count_users.py
```

# **8. Auteur**

Projet rÃ©alisÃ© par **Yanis Dabin**,
dans le cadre du module **DonnÃ©es Massives & Cloud â€” 2025**.
